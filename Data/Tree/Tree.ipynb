{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from pycorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load(tsv_file):\n",
    "    return pd.read_csv(tsv_file, header=0, sep=\"\\t\", index_col=False)\n",
    "\n",
    "amazon = load(\"../Raw/amazon.tsv\")\n",
    "imdb   = load(\"../Raw/imdb.tsv\")\n",
    "yelp   = load(\"../Raw/yelp.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject and Opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract (subject, opinion, sentiment) triplet.\n",
    "\n",
    "# Start server first, remember to shut down when done.\n",
    "# java -mx5g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -timeout 10000\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "def get_subject_opinion_sentiment(sentence, sentiment):\n",
    "    \n",
    "    # [[Subject, Opinion, Sentiment], ...]\n",
    "    triplet = []\n",
    "    \n",
    "    # Stanford Sentence Parser.\n",
    "    res = nlp.annotate(sentence.translate(str.maketrans(',.', '  ')).lower(),\n",
    "                       properties={\n",
    "            'annotators': 'depparse',\n",
    "            'outputFormat': 'json',\n",
    "            'timeout': 100000,\n",
    "        })\n",
    "    \n",
    "    if len(res[\"sentences\"]) == 0:\n",
    "        return triplet\n",
    "    \n",
    "    current = []\n",
    "    negation = []\n",
    "    \n",
    "    for x in res[\"sentences\"][0][\"basicDependencies\"]:\n",
    "        \n",
    "        # If negation found.\n",
    "        if 'neg' in x[\"dep\"]:\n",
    "            negation.append([x[\"governorGloss\"], x[\"dependentGloss\"]])\n",
    "            continue\n",
    "        \n",
    "        # If dependency found.\n",
    "        if 'mod' in x[\"dep\"] or 'dep' in x[\"dep\"]:\n",
    "            \n",
    "            # If governor is a noun and depedent is an adjective.                \n",
    "            if 'NN' in nltk.pos_tag([x[\"governorGloss\"]])[0][1] and 'JJ' in nltk.pos_tag([x[\"dependentGloss\"]])[0][1]:\n",
    "                current.append([x[\"governorGloss\"], x[\"dependentGloss\"], sentiment])\n",
    "            continue\n",
    "        \n",
    "        # If relation found.\n",
    "        if 'nsubj' in x[\"dep\"]:\n",
    "            \n",
    "            # If governor is an adjective and dependent is a noun.\n",
    "            if 'JJ' in nltk.pos_tag([x[\"governorGloss\"]])[0][1] and 'NN' in nltk.pos_tag([x[\"dependentGloss\"]])[0][1]:\n",
    "                current.append([x[\"dependentGloss\"], x[\"governorGloss\"], sentiment])\n",
    "            continue\n",
    "    \n",
    "    # Add negations.\n",
    "    for n in negation:\n",
    "        for i in range(len(current)):\n",
    "            if n[0] == current[i][1]:\n",
    "                current[i][1] = n[1] + \" \" + current[i][1]\n",
    "    \n",
    "    # Append to list.\n",
    "    triplet.extend(current)\n",
    "    \n",
    "    return triplet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Chart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def write(data, json_file, N):\n",
    "    sentences  = [ str(s) for s in data['review'].values.tolist() ]\n",
    "    sentiments = [ int(i) for i in data['sentiment'].values.tolist() ]\n",
    "    \n",
    "    subject_dict = {}\n",
    "    for i in range(len(sentences)):\n",
    "        triplets = get_subject_opinion_sentiment(sentences[i], sentiments[i])\n",
    "        \n",
    "        for t in triplets:\n",
    "            if t[0] not in subject_dict:\n",
    "                subject_dict[t[0]] = {}\n",
    "            \n",
    "            if t[1] not in subject_dict[t[0]]:\n",
    "                subject_dict[t[0]][t[1]] = [0, 0] # [Negative, Positive]\n",
    "            \n",
    "            subject_dict[t[0]][t[1]][t[2]] += 1\n",
    "    \n",
    "    subject_json = []\n",
    "    for k in subject_dict.keys():\n",
    "        \n",
    "        node_children = []\n",
    "        node_sentiment = [0, 0]\n",
    "        \n",
    "        for c in subject_dict[k]:\n",
    "            node_children.append({\"name\": c, \"sentiment\": subject_dict[k][c]})\n",
    "            node_sentiment[0] += subject_dict[k][c][0]\n",
    "            node_sentiment[1] += subject_dict[k][c][1]\n",
    "        \n",
    "        subject_json.append({\"name\": k, \"sentiment\": node_sentiment, \"children\": node_children})\n",
    "        \n",
    "    subject_json = sorted(subject_json, key=lambda x: x[\"sentiment\"][0] + x[\"sentiment\"][1], reverse=True)[0:min(len(subject_json), N)]\n",
    "    \n",
    "    root_sentiment = [0, 0]\n",
    "    \n",
    "    for s in subject_json:\n",
    "        root_sentiment[0] += s[\"sentiment\"][0]\n",
    "        root_sentiment[1] += s[\"sentiment\"][1]\n",
    "        \n",
    "    subject_json = {\n",
    "        \"name\": \"root\",\n",
    "        \"sentiment\": root_sentiment,\n",
    "        \"children\": subject_json\n",
    "    }\n",
    "    \n",
    "    with open(json_file, 'w') as file:\n",
    "        json.dump(subject_json, file)\n",
    "\n",
    "write(amazon, \"amazon_tree.json\", 5)\n",
    "write(imdb, \"imdb_tree.json\", 5)\n",
    "write(yelp, \"yelp_tree.json\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
